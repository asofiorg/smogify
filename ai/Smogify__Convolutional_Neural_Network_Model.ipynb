{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp9sjqR5TnRh"
      },
      "source": [
        "# Convolutional Neural Network (CNN) Model for Image Classification of Smog vs Clear images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KcniVHSTvxS"
      },
      "source": [
        "Import all libraries and set environment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQNaOO9YEPIW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrzuMuUNUyH5"
      },
      "source": [
        "install TFlearn from Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLsOybt4GJvg",
        "outputId": "40024503-9b82-4d71-d63d-4cd11e7b5408"
      },
      "outputs": [],
      "source": [
        "!pip install tflearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2iYMaUPF2Kx"
      },
      "outputs": [],
      "source": [
        "import tflearn\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.estimator import regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f393tt5fGZpw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5LANl3PHOPl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4boi0NUeSvdc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHan9rPT1CH"
      },
      "source": [
        "For collaboration, imported data from google drive || Run also using locally using Jupyter Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24HTT3QjS-Ap",
        "outputId": "99ae773a-43d9-4416-9ff4-94e58a2f55fe"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBxj0vOGUCGu"
      },
      "source": [
        "Assignening data into variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "c5RujvoBEXQ7",
        "outputId": "980b9d8f-8bd5-4a4c-e8e7-498146798c21"
      },
      "outputs": [],
      "source": [
        "# Training and Testing data \n",
        "\n",
        "entrenamiento = #Path training data || Drive\n",
        "dtest = #Path Testing Data || Drive\n",
        "\n",
        "LR = 1e-3\n",
        "tamano= 50 ## Figure size || Subject to change depending on data pre-processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_lCZ5DiU6Oa"
      },
      "source": [
        "### Creating the model as a basic CNN formated 1e -3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41lJR9tNEfns"
      },
      "outputs": [],
      "source": [
        "#Model\n",
        "modelo = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v03x83yBVD_5"
      },
      "source": [
        "### Labelling the data (Smog vs clear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ4tFLLDEjvY"
      },
      "outputs": [],
      "source": [
        "#Def to Label\n",
        "def label_img(img):\n",
        "\tword_label = img.split('.')[-3]\n",
        "\tif word_label == 'smog': return [1, 0]\n",
        "\telif word_label == 'clear': return [0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdEt6oMeVSJg"
      },
      "source": [
        "### Creating Dataset only for training data \n",
        "Missing a couple shape details / for image size "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTEtp0M-Erl-"
      },
      "outputs": [],
      "source": [
        "def ctd(): \n",
        "\ttraining_data = []\n",
        "\tfor img in tqdm(os.listdir(entrenamiento)):\n",
        "\t\tlabel = label_img(img)\n",
        "\t\tpath = os.path.join(entrenamiento, img)\n",
        "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\t\t#reshpae \n",
        "\t\timg = cv2.resize(img, (tamano, tamano))\n",
        "\t\ttraining_data.append([np.array(img), np.array(label)])\n",
        "\t# Preservar random \n",
        "\tshuffle(training_data)\n",
        "\tnp.save('train_data.npy', training_data)\n",
        "\treturn training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0UctKpNVlnP"
      },
      "source": [
        "### Procesing test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqaQR6stE0jh"
      },
      "outputs": [],
      "source": [
        "def ptd(): \n",
        "\ttesting_data = []\n",
        "\tfor img in tqdm(os.listdir(dtest)):\n",
        "\t\tpath = os.path.join(dtest, img)\n",
        "\t\timg_num = img.split('.')[0]\n",
        "\t\timg = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\t\timg = cv2.resize(img, (tamano, tamano))\n",
        "\t\ttesting_data.append([np.array(img), img_num])\n",
        "\t\t\n",
        "\tshuffle(testing_data)\n",
        "\tnp.save('test_data.npy', testing_data)\n",
        "\treturn testing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhYaautAVsE9"
      },
      "source": [
        "Assign data to train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2iYdMUtVvU5"
      },
      "outputs": [],
      "source": [
        "train_data = ctd()\n",
        "test_data = ptd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQwf-O0WVw0o"
      },
      "source": [
        "## Creat CNN : 2d "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "rALGE-sgFaIt",
        "outputId": "4343aac9-5f31-4df5-b01f-550da7fe2cf7"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "#Layer 1\n",
        "convnet = input_data(shape =[None, tamano, tamano, 1], name ='input')\n",
        "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
        "#Layer 2\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
        "#Layer 3\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 128, 5, activation ='relu')\n",
        "#Layer 4\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 64, 5, activation ='relu')\n",
        "#Layer 5\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "convnet = conv_2d(convnet, 32, 5, activation ='relu')\n",
        "\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "#Fully connected CNN \n",
        "convnet = fully_connected(convnet, 1024, activation ='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "convnet = fully_connected(convnet, 2, activation ='softmax')\n",
        "convnet = regression(convnet, optimizer ='adam', learning_rate = LR,\n",
        "\tloss ='categorical_crossentropy', name ='targets')\n",
        "model = tflearn.DNN(convnet, tensorboard_dir ='log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYabB_1lWDth"
      },
      "source": [
        "Store data to start training with same shape each "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "yXAY_cClG2FF",
        "outputId": "9dea9e17-7567-404a-b6e0-1f5838cd6fa7"
      },
      "outputs": [],
      "source": [
        "train = train_data[:-500]\n",
        "test = train_data[-500:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYXh9E2fWI4z"
      },
      "source": [
        "Fianl split of data, ready to fit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "BQXN4xlLG6qZ",
        "outputId": "8e9cf1bf-802b-4460-d889-40ecfa91fc4b"
      },
      "outputs": [],
      "source": [
        "X = np.array([i[0] for i in train]).reshape(-1, tamano, tamano, 1)\n",
        "Y = [i[1] for i in train]\n",
        "test_x = np.array([i[0] for i in test]).reshape(-1, tamano, tamano, 1)\n",
        "test_y = [i[1] for i in test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AvnYldcWP-X"
      },
      "source": [
        "### Fit model using 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIf5NIaLG-Cu"
      },
      "outputs": [],
      "source": [
        "#Datos en el modelo con 5 epochs \n",
        "model.fit({'input': X}, {'targets': Y}, n_epoch = 5,\n",
        "\tvalidation_set =({'input': test_x}, {'targets': test_y}),\n",
        "\tsnapshot_step = 500, show_metric = True, run_id = modelo)\n",
        "model.save(modelo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Smogify_ Convolutional Neural Network_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
